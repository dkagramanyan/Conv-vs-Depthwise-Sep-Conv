{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras.applications import imagenet_utils\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.keras.layers import VersionAwareLayers\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "x_train = tf.keras.applications.resnet50.preprocess_input(x_train.astype(np.float32))\n",
    "x_test = tf.keras.applications.resnet50.preprocess_input(x_test.astype(np.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def define_resnet50():\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "    resized = tf.keras.layers.UpSampling2D(size=(7, 7))(inputs)\n",
    "\n",
    "    features = tf.keras.applications.ResNet50(input_shape=(224, 224, 3),\n",
    "                                              include_top=False,\n",
    "                                              weights='imagenet')(resized)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(features)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = define_resnet50()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def resnet_conv_block(input_shape, filters, conv_shortcut, name, model_name, kernel_size=3, stride=1, DW=False):\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "    bn_axis = 3\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(\n",
    "            4 * filters, 1, strides=stride, name=name + '_0_conv')(inputs)\n",
    "        shortcut = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "\n",
    "    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(inputs)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    # Conv2D 3x3\n",
    "    if not DW:\n",
    "        #conv\n",
    "        x = layers.Conv2D(\n",
    "            filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "        x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='SAME', name=name + '_2_DWconv')(x)\n",
    "        x = layers.Conv2D(\n",
    "            filters, kernel_size=1, padding='SAME', name=name + '_2_conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "        pass\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "# def define_modular_resnet50(load_conv_weights=False, folder='weights', dw_indx=1):\n",
    "#     global layers\n",
    "load_conv_weights = True\n",
    "folder = 'weights'\n",
    "dw_indx = 30\n",
    "\n",
    "layers = VersionAwareLayers()\n",
    "\n",
    "use_bias = True\n",
    "bn_axis = 3\n",
    "\n",
    "\n",
    "def before_conv_model(inputs):\n",
    "    resized = tf.keras.layers.UpSampling2D(size=(7, 7))(inputs)\n",
    "    x = layers.ZeroPadding2D(\n",
    "        padding=((3, 3), (3, 3)), name='conv1_pad')(resized)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name='input_resize')\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "input_resize_model = before_conv_model(inputs)\n",
    "\n",
    "x = input_resize_model(inputs)\n",
    "\n",
    "# 3 blocks\n",
    "model_conv2_1 = resnet_conv_block(input_shape=x.shape[1:], filters=64, conv_shortcut=True, name='conv2',\n",
    "                                  model_name='block_conv2_1', stride=1,\n",
    "                                  DW=True if dw_indx == 1 or dw_indx == 0 else False)\n",
    "x = model_conv2_1(x)\n",
    "model_conv2_2 = resnet_conv_block(input_shape=x.shape[1:], filters=64, conv_shortcut=False, name='conv2',\n",
    "                                  model_name='block_conv2_2', stride=1,\n",
    "                                  DW=True if dw_indx == 2 or dw_indx == 0 else False)\n",
    "x = model_conv2_2(x)\n",
    "model_conv2_3 = resnet_conv_block(input_shape=x.shape[1:], filters=64, conv_shortcut=False, name='conv2',\n",
    "                                  model_name='block_conv2_3', stride=1,\n",
    "                                  DW=True if dw_indx == 3 or dw_indx == 0 else False)\n",
    "x = model_conv2_3(x)\n",
    "\n",
    "# 4 blocks\n",
    "model_conv3_1 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=True, name='conv3',\n",
    "                                  model_name='block_conv3_1', stride=2,\n",
    "                                  DW=True if dw_indx == 4 or dw_indx == 0 else False)\n",
    "x = model_conv3_1(x)\n",
    "model_conv3_2 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=False, name='conv3',\n",
    "                                  model_name='block_conv3_2', stride=1,\n",
    "                                  DW=True if dw_indx == 5 or dw_indx == 0 else False)\n",
    "x = model_conv3_2(x)\n",
    "model_conv3_3 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=False, name='conv3',\n",
    "                                  model_name='block_conv3_3', stride=1,\n",
    "                                  DW=True if dw_indx == 6 or dw_indx == 0 else False)\n",
    "x = model_conv3_3(x)\n",
    "model_conv3_4 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=False, name='conv3',\n",
    "                                  model_name='block_conv3_4', stride=1,\n",
    "                                  DW=True if dw_indx == 7 or dw_indx == 0 else False)\n",
    "x = model_conv3_4(x)\n",
    "\n",
    "# 6 blocks\n",
    "model_conv4_1 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=True, name='conv4',\n",
    "                                  model_name='block_conv4_1', stride=1,\n",
    "                                  DW=True if dw_indx == 8 or dw_indx == 0 else False)\n",
    "x = model_conv4_1(x)\n",
    "model_conv4_2 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                  model_name='block_conv4_2', stride=1,\n",
    "                                  DW=True if dw_indx == 9 or dw_indx == 0 else False)\n",
    "x = model_conv4_2(x)\n",
    "model_conv4_3 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                  model_name='block_conv4_3', stride=1,\n",
    "                                  DW=True if dw_indx == 10 or dw_indx == 0 else False)\n",
    "x = model_conv4_3(x)\n",
    "model_conv4_4 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                  model_name='block_conv4_4', stride=1,\n",
    "                                  DW=True if dw_indx == 11 or dw_indx == 0 else False)\n",
    "x = model_conv4_4(x)\n",
    "model_conv4_5 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                  model_name='block_conv4_5', stride=1,\n",
    "                                  DW=True if dw_indx == 12 or dw_indx == 0 else False)\n",
    "x = model_conv4_5(x)\n",
    "model_conv4_6 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                  model_name='block_conv4_6', stride=1,\n",
    "                                  DW=True if dw_indx == 13 or dw_indx == 0 else False)\n",
    "x = model_conv4_6(x)\n",
    "\n",
    "# 3 blocks\n",
    "model_conv5_1 = resnet_conv_block(input_shape=x.shape[1:], filters=512, conv_shortcut=True, name='conv5',\n",
    "                                  model_name='block_conv5_1', stride=1,\n",
    "                                  DW=True if dw_indx == 14 or dw_indx == 0 else False)\n",
    "x = model_conv5_1(x)\n",
    "model_conv5_2 = resnet_conv_block(input_shape=x.shape[1:], filters=512, conv_shortcut=False, name='conv5',\n",
    "                                  model_name='block_conv5_2', stride=1,\n",
    "                                  DW=True if dw_indx == 15 or dw_indx == 0 else False)\n",
    "x = model_conv5_2(x)\n",
    "model_conv5_3 = resnet_conv_block(input_shape=x.shape[1:], filters=512, conv_shortcut=False, name='conv5',\n",
    "                                  model_name='block_conv5_3', stride=1,\n",
    "                                  DW=True if dw_indx == 16 or dw_indx == 0 else False)\n",
    "x = model_conv5_3(x)\n",
    "\n",
    "\n",
    "def classifier(input_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name='classifier_model')\n",
    "\n",
    "\n",
    "classifier_model = classifier(x.shape[1:])\n",
    "x = classifier_model(x)\n",
    "\n",
    "models_dict = {'classifier_model': classifier_model,\n",
    "               'input_resize_model': input_resize_model,\n",
    "               'model_conv2_1': model_conv2_1,\n",
    "               'model_conv2_2': model_conv2_2,\n",
    "               'model_conv2_3': model_conv2_3,\n",
    "               'model_conv3_1': model_conv3_1,\n",
    "               'model_conv3_2': model_conv3_2,\n",
    "               'model_conv3_3': model_conv3_3,\n",
    "               'model_conv3_4': model_conv3_4,\n",
    "               'model_conv4_1': model_conv4_1,\n",
    "               'model_conv4_2': model_conv4_2,\n",
    "               'model_conv4_3': model_conv4_3,\n",
    "               'model_conv4_4': model_conv4_4,\n",
    "               'model_conv4_5': model_conv4_5,\n",
    "               'model_conv4_6': model_conv4_6,\n",
    "               'model_conv5_1': model_conv5_1,\n",
    "               'model_conv5_2': model_conv5_2,\n",
    "               'model_conv5_3': model_conv5_3}\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "if load_conv_weights:\n",
    "\n",
    "    # doesn't working\n",
    "    # for i, name in enumerate(list(models_dict.keys())):\n",
    "    #     if i != dw_indx:\n",
    "    #\n",
    "    #         models_dict[name].load_weights(folder + '/' + name + '/conv_weights.h5')\n",
    "    # input_resize_model.load_weights(folder + '/input_resize.h5')\n",
    "    # classifier_model.load_weights(folder + '/classifier.h5')\n",
    "\n",
    "    if dw_indx != 1:\n",
    "        model_conv2_1.load_weights(folder + '/model_conv2_1/conv_weights.h5')\n",
    "    if dw_indx != 2:\n",
    "        model_conv2_2.load_weights(folder + '/model_conv2_2/conv_weights.h5')\n",
    "    if dw_indx != 3:\n",
    "        model_conv2_3.load_weights(folder + '/model_conv2_3/conv_weights.h5')\n",
    "\n",
    "    # 4 blocks\n",
    "    if dw_indx != 4:\n",
    "        model_conv3_1.load_weights(folder + '/model_conv3_1/conv_weights.h5')\n",
    "    if dw_indx != 5:\n",
    "        model_conv3_2.load_weights(folder + '/model_conv3_2/conv_weights.h5')\n",
    "    if dw_indx != 6:\n",
    "        model_conv3_3.load_weights(folder + '/model_conv3_3/conv_weights.h5')\n",
    "    if dw_indx != 7:\n",
    "        model_conv3_4.load_weights(folder + '/model_conv3_4/conv_weights.h5')\n",
    "\n",
    "    # 6 blocks\n",
    "    if dw_indx != 8:\n",
    "        model_conv4_1.load_weights(folder + '/model_conv4_1/conv_weights.h5')\n",
    "    if dw_indx != 9:\n",
    "        model_conv4_2.load_weights(folder + '/model_conv4_2/conv_weights.h5')\n",
    "    if dw_indx != 10:\n",
    "        model_conv4_3.load_weights(folder + '/model_conv4_3/conv_weights.h5')\n",
    "    if dw_indx != 11:\n",
    "        model_conv4_4.load_weights(folder + '/model_conv4_4/conv_weights.h5')\n",
    "    if dw_indx != 12:\n",
    "        model_conv4_5.load_weights(folder + '/model_conv4_5/conv_weights.h5')\n",
    "    if dw_indx != 13:\n",
    "        model_conv4_6.load_weights(folder + '/model_conv4_6/conv_weights.h5')\n",
    "\n",
    "    # 3 blocks\n",
    "    if dw_indx != 14:\n",
    "        model_conv5_1.load_weights(folder + '/model_conv5_1/conv_weights.h5')\n",
    "    if dw_indx != 15:\n",
    "        model_conv5_2.load_weights(folder + '/model_conv5_2/conv_weights.h5')\n",
    "    if dw_indx != 16:\n",
    "        model_conv5_3.load_weights(folder + '/model_conv5_3/conv_weights.h5')\n",
    "    # return model, models_dict\n",
    "\n",
    "# model, models_dict = define_modular_resnet50(load_conv_weights=True,dw_indx=30)\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "# optim = optimizers.RMSprop(centered=False, learning_rate=0.001)\n",
    "optim = optimizers.Adam(learning_rate=0.001, amsgrad=True)\n",
    "# optim=optimizers.SGD(learning_rate=0.0001,nesterov=True)\n",
    "# optim=optimizers.Adadelta(learning_rate=0.001)\n",
    "model.compile(optimizer=optim, metrics=['accuracy'], loss='sparse_categorical_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "# model.load_weights('modular_resnet_acc_train=0.84_test=0.79.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 73/556 [==>...........................] - ETA: 5:06 - loss: 1.6451 - accuracy: 0.3682"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-216-97dc5cf2757f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m model.fit(x_train, y_train, batch_size=90, epochs=100, validation_data=(x_test, y_test), shuffle=True,\n\u001B[0m\u001B[0;32m      2\u001B[0m           callbacks=[model_checkpoint_callback])\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1103\u001B[0m               \u001B[0mlogs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtmp_logs\u001B[0m  \u001B[1;31m# No error, now safe to assign to logs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m               \u001B[0mend_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep_increment\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1105\u001B[1;33m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mend_step\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1106\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop_training\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1107\u001B[0m                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001B[0m in \u001B[0;36mon_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    452\u001B[0m     \"\"\"\n\u001B[0;32m    453\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_should_call_train_batch_hooks\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 454\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_batch_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mModeKeys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'end'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    455\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mon_test_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001B[0m in \u001B[0;36m_call_batch_hook\u001B[1;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[0;32m    294\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_batch_begin_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mhook\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'end'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 296\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_batch_end_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    297\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Unrecognized hook: {}'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001B[0m in \u001B[0;36m_call_batch_end_hook\u001B[1;34m(self, mode, batch, logs)\u001B[0m\n\u001B[0;32m    314\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_batch_times\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_time\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 316\u001B[1;33m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_batch_hook_helper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhook_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    317\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    318\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_batch_times\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_batches_for_timing_check\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001B[0m in \u001B[0;36m_call_batch_hook_helper\u001B[1;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[0;32m    354\u001B[0m       \u001B[0mhook\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcallback\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    355\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcallback\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'_supports_tf_logs'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 356\u001B[1;33m         \u001B[0mhook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    357\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    358\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnumpy_logs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Only convert once.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001B[0m in \u001B[0;36mon_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1018\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1019\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mon_train_batch_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1020\u001B[1;33m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_batch_update_progbar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1021\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1022\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mon_test_batch_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001B[0m in \u001B[0;36m_batch_update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1082\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1083\u001B[0m       \u001B[1;31m# Only block async when verbose = 1.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1084\u001B[1;33m       \u001B[0mlogs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy_or_python_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1085\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprogbar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfinalize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1086\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001B[0m in \u001B[0;36mto_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    512\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m  \u001B[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    513\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 514\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_to_single_numpy_or_python_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    515\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001B[0m in \u001B[0;36m_to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    508\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_to_single_numpy_or_python_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    509\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 510\u001B[1;33m       \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    511\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    512\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m  \u001B[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1069\u001B[0m     \"\"\"\n\u001B[0;32m   1070\u001B[0m     \u001B[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1071\u001B[1;33m     \u001B[0mmaybe_arr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1072\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmaybe_arr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mmaybe_arr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1073\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1035\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1036\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1037\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_numpy_internal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1038\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1039\u001B[0m       \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=90, epochs=100, validation_data=(x_test, y_test), shuffle=True,\n",
    "          callbacks=[model_checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "model.save_weights('modular_resnet_acc_train=0.xx_test=0.xx.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def eval_model(model, x_train, y_train, x_test, y_test):\n",
    "    print('train data\\n', model.evaluate(x_train, y_train), '\\n')\n",
    "    print('test data\\n', model.evaluate(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 201/1563 [==>...........................] - ETA: 1:45 - loss: 2.6873 - accuracy: 0.0859"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-201-58542abe4ba6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0meval_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-172-1a5a0365e69a>\u001B[0m in \u001B[0;36meval_model\u001B[1;34m(model, x_train, y_train, x_test, y_test)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0meval_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'train data\\n'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'test data\\n'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[0;32m   1387\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'test'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1388\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1389\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1390\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1391\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 828\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"xla\"\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    853\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    854\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 855\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    856\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    857\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2940\u001B[0m       (graph_function,\n\u001B[0;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2942\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2944\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1916\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1917\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1918\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1919\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    553\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    556\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "eval_model(model, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "def save_modules_weights(folder, models_dict):\n",
    "    names = list(models_dict.keys())\n",
    "    for name in names:\n",
    "        if not os.path.exists(folder + '/' + name):\n",
    "            os.mkdir(folder + '/' + name)\n",
    "        models_dict[name].save_weights(folder + '/' + name + '/conv_weights.h5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "save_modules_weights('weights', models_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning pipeline for resnet modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}