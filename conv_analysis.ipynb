{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras.applications import imagenet_utils\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.keras.layers import VersionAwareLayers\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "x_train = tf.keras.applications.resnet50.preprocess_input(x_train.astype(np.float32))\n",
    "x_test = tf.keras.applications.resnet50.preprocess_input(x_test.astype(np.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def resnet_conv_block(input_shape, filters, conv_shortcut, name, model_name, kernel_size=3, stride=1, DW=False):\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "    bn_axis = 3\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(\n",
    "            4 * filters, 1, strides=stride, name=name + '_0_conv')(inputs)\n",
    "        shortcut = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "\n",
    "    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(inputs)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    # Conv2D 3x3\n",
    "    if not DW:\n",
    "        #conv\n",
    "        x = layers.Conv2D(\n",
    "            filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "        x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "    else:\n",
    "        pw_filters = _make_divisible(filters, 8)\n",
    "        x = tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='SAME', name=name + '_2_DWconv')(x)\n",
    "\n",
    "        x = layers.BatchNormalization(axis=bn_axis,\n",
    "                                      epsilon=1e-3,\n",
    "                                      momentum=0.999,\n",
    "                                      name=name + 'depthwise_BN')(x)\n",
    "\n",
    "        x = layers.ReLU(6., name=name + 'depthwise_relu')(x)\n",
    "        x = layers.Conv2D(\n",
    "            pw_filters, kernel_size=1, padding='SAME', name=name + '_2_conv')(x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "        pass\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def define_modular_resnet50(load_conv_weights=False, load_dw_conv_weights_index=[], folder='weights', dw_indxs=[]):\n",
    "    global layers\n",
    "    layers = VersionAwareLayers()\n",
    "\n",
    "    use_bias = True\n",
    "    bn_axis = 3\n",
    "\n",
    "    def before_conv_model(inputs):\n",
    "        resized = tf.keras.layers.UpSampling2D(size=(7, 7))(inputs)\n",
    "        x = layers.ZeroPadding2D(\n",
    "            padding=((3, 3), (3, 3)), name='conv1_pad')(resized)\n",
    "        x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "        x = layers.Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "        x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "        x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "        return tf.keras.Model(inputs=inputs, outputs=x, name='input_resize')\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "    input_resize_model = before_conv_model(inputs)\n",
    "\n",
    "    x = input_resize_model(inputs)\n",
    "\n",
    "    # 3 blocks\n",
    "    model_conv2_1 = resnet_conv_block(input_shape=x.shape[1:], filters=64, conv_shortcut=True, name='conv2',\n",
    "                                      model_name='block_conv2_1', stride=1,\n",
    "                                      DW=0 in dw_indxs)\n",
    "    x = model_conv2_1(x)\n",
    "    model_conv2_2 = resnet_conv_block(input_shape=x.shape[1:], filters=64, conv_shortcut=False, name='conv2',\n",
    "                                      model_name='block_conv2_2', stride=1,\n",
    "                                      DW=1 in dw_indxs)\n",
    "    x = model_conv2_2(x)\n",
    "    model_conv2_3 = resnet_conv_block(input_shape=x.shape[1:], filters=64, conv_shortcut=False, name='conv2',\n",
    "                                      model_name='block_conv2_3', stride=1,\n",
    "                                      DW=2 in dw_indxs)\n",
    "    x = model_conv2_3(x)\n",
    "\n",
    "    # 4 blocks\n",
    "    model_conv3_1 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=True, name='conv3',\n",
    "                                      model_name='block_conv3_1', stride=2,\n",
    "                                      DW=3 in dw_indxs)\n",
    "    x = model_conv3_1(x)\n",
    "    model_conv3_2 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=False, name='conv3',\n",
    "                                      model_name='block_conv3_2', stride=1,\n",
    "                                      DW=4 in dw_indxs)\n",
    "    x = model_conv3_2(x)\n",
    "    model_conv3_3 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=False, name='conv3',\n",
    "                                      model_name='block_conv3_3', stride=1,\n",
    "                                      DW=5 in dw_indxs)\n",
    "    x = model_conv3_3(x)\n",
    "    model_conv3_4 = resnet_conv_block(input_shape=x.shape[1:], filters=128, conv_shortcut=False, name='conv3',\n",
    "                                      model_name='block_conv3_4', stride=1,\n",
    "                                      DW=6 in dw_indxs)\n",
    "    x = model_conv3_4(x)\n",
    "\n",
    "    # 6 blocks\n",
    "    model_conv4_1 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=True, name='conv4',\n",
    "                                      model_name='block_conv4_1', stride=1,\n",
    "                                      DW=7 in dw_indxs)\n",
    "    x = model_conv4_1(x)\n",
    "    model_conv4_2 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                      model_name='block_conv4_2', stride=1,\n",
    "                                      DW=8 in dw_indxs)\n",
    "    x = model_conv4_2(x)\n",
    "    model_conv4_3 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                      model_name='block_conv4_3', stride=1,\n",
    "                                      DW=9 in dw_indxs)\n",
    "    x = model_conv4_3(x)\n",
    "    model_conv4_4 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                      model_name='block_conv4_4', stride=1,\n",
    "                                      DW=10 in dw_indxs)\n",
    "    x = model_conv4_4(x)\n",
    "    model_conv4_5 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                      model_name='block_conv4_5', stride=1,\n",
    "                                      DW=11 in dw_indxs)\n",
    "    x = model_conv4_5(x)\n",
    "    model_conv4_6 = resnet_conv_block(input_shape=x.shape[1:], filters=256, conv_shortcut=False, name='conv4',\n",
    "                                      model_name='block_conv4_6', stride=1,\n",
    "                                      DW=12 in dw_indxs)\n",
    "    x = model_conv4_6(x)\n",
    "\n",
    "    # 3 blocks\n",
    "    model_conv5_1 = resnet_conv_block(input_shape=x.shape[1:], filters=512, conv_shortcut=True, name='conv5',\n",
    "                                      model_name='block_conv5_1', stride=1,\n",
    "                                      DW=13 in dw_indxs)\n",
    "    x = model_conv5_1(x)\n",
    "    model_conv5_2 = resnet_conv_block(input_shape=x.shape[1:], filters=512, conv_shortcut=False, name='conv5',\n",
    "                                      model_name='block_conv5_2', stride=1,\n",
    "                                      DW=14 in dw_indxs)\n",
    "    x = model_conv5_2(x)\n",
    "    model_conv5_3 = resnet_conv_block(input_shape=x.shape[1:], filters=512, conv_shortcut=False, name='conv5',\n",
    "                                      model_name='block_conv5_3', stride=1,\n",
    "                                      DW=15 in dw_indxs)\n",
    "    x = model_conv5_3(x)\n",
    "\n",
    "    def classifier(input_shape):\n",
    "        inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "        return tf.keras.Model(inputs=inputs, outputs=x, name='classifier_model')\n",
    "\n",
    "    classifier_model = classifier(x.shape[1:])\n",
    "    x = classifier_model(x)\n",
    "\n",
    "    models_dict = {\n",
    "        'model_conv2_1': model_conv2_1,\n",
    "        'model_conv2_2': model_conv2_2,\n",
    "        'model_conv2_3': model_conv2_3,\n",
    "        'model_conv3_1': model_conv3_1,\n",
    "        'model_conv3_2': model_conv3_2,\n",
    "        'model_conv3_3': model_conv3_3,\n",
    "        'model_conv3_4': model_conv3_4,\n",
    "        'model_conv4_1': model_conv4_1,\n",
    "        'model_conv4_2': model_conv4_2,\n",
    "        'model_conv4_3': model_conv4_3,\n",
    "        'model_conv4_4': model_conv4_4,\n",
    "        'model_conv4_5': model_conv4_5,\n",
    "        'model_conv4_6': model_conv4_6,\n",
    "        'model_conv5_1': model_conv5_1,\n",
    "        'model_conv5_2': model_conv5_2,\n",
    "        'model_conv5_3': model_conv5_3,\n",
    "        'classifier_model': classifier_model,\n",
    "        'input_resize_model': input_resize_model}\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    if load_conv_weights:\n",
    "\n",
    "        for i, name in enumerate(list(models_dict.keys())):\n",
    "            # print(i)\n",
    "            if i not in dw_indxs:\n",
    "                models_dict[name].load_weights(folder + '/' + name + '/conv_weights.h5')\n",
    "\n",
    "        input_resize_model.load_weights(folder + '/input_resize_model/conv_weights.h5')\n",
    "        classifier_model.load_weights(folder + '/classifier_model/conv_weights.h5')\n",
    "\n",
    "    if len(load_dw_conv_weights_index)!=0:\n",
    "        for index in load_dw_index:\n",
    "            name=list(models_dict.keys())[index]\n",
    "            models_dict[name].load_weights(folder + '/' + name + '/dw_conv_weights.h5')\n",
    "\n",
    "    return model, models_dict\n",
    "\n",
    "# 3,5 unsuccessful\n",
    "\n",
    "dw_index = [0,1,2,4,8,10,11,12,14,15]\n",
    "# dw_index = [0,1,]\n",
    "load_dw_index=[0,1,2,4,8,10,11,12,14,15]\n",
    "load_weights = True\n",
    "model, models_dict = define_modular_resnet50(load_conv_weights=load_weights, load_dw_conv_weights_index=load_dw_index,\n",
    "                                             dw_indxs=dw_index)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optim = optimizers.RMSprop(centered=True, learning_rate=0.00001)\n",
    "optim = optimizers.Adam(learning_rate=0.00001, amsgrad=True)\n",
    "# optim=optimizers.SGD(learning_rate=0.00001,nesterov=True)\n",
    "# optim = optimizers.Adadelta(learning_rate=0.00001,rho=0.8)\n",
    "model.compile(optimizer=optim, metrics=['accuracy'], loss='sparse_categorical_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(f'modular_resnet_{dw_index}.h5')\n",
    "# model.load_weights('checkpoints/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), shuffle=True,\n",
    "          callbacks=[model_checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_weights(f'modular_resnet_{dw_index}.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model(model, x_train, y_train, x_test, y_test):\n",
    "    print('train data\\n', model.evaluate(x_train, y_train), '\\n')\n",
    "    print('test data\\n', model.evaluate(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_model(model, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_modules_weights(folder, models_dict, dw_index, save_all=False):\n",
    "    names = list(models_dict.keys())\n",
    "    for i, name in enumerate(names[:-2]):\n",
    "        if not os.path.exists(folder + '/' + name):\n",
    "            os.mkdir(folder + '/' + name)\n",
    "\n",
    "        if i in dw_index:\n",
    "            models_dict[name].save_weights(folder + '/' + name + '/dw_conv_weights.h5')\n",
    "        else:\n",
    "            if save_all:\n",
    "                models_dict[name].save_weights(folder + '/' + name + '/conv_weights.h5')\n",
    "\n",
    "    if save_all:\n",
    "        models_dict['input_resize_model'].save_weights(folder + '/input_resize_model/conv_weights.h5')\n",
    "        models_dict['classifier_model'].save_weights(folder + '/classifier_model/conv_weights.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_modules_weights('weights', models_dict, dw_index, save_all=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning pipeline for resnet modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}